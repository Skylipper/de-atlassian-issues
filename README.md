# Проект по агрегированию данных из публичной облачной JIRA компании ATLASSIAN
Идея проекта заключается в получении информации о задачах в трекере за большой период времени через REST API и построении витрин и визуализаций на основе этих данных.

## Что проверяем:

1. Действительно ли для серверных версий продукта, отмеченных как LTS, количество багов, зарегистрированных пользователями меньше, чем для не-LTS.
2. Действительно ли ATLASSIAN отдает приоритет задачам, относящимся к Cloud.
3. Действительно ли количество голосов за улучшение может повлиять на внедрение функциональности.


## Реализация

### Технологический стэк
Python - основной язык программирования 

Apache Airflow - оркестратор для пайплайнов обработки данных.

PostgreSQL - СУБД для организации слоев STG, ODS и DDS слоев.

СlickHouse - аналитическая СУБД для CDM слоя

Apache Spark - перенос данных из PostgreSQL в СlickHouse

DataLens - визуализация.

### Описание пайплайна
#### Загрузка в STG
STG слой расположен в отдельной схеме на БД под управлением PostgreSQL.

Схема слоя:

![stg](https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/db_scheme/1_stg.png)

Таблицы не имеют внешних ключей, проверяется уникальность ID. 
При обновлении объекта данные перезаписываются.

1. Загрузка доступных задач через REST API: через JQL-фильтр (нужны два проекта JRACLOUD и JRASERVER) получаем всю информацию о задачах (используется expand).
Есть ограничения на количество запросов в минуту, поэтому загружаем задачи батчами по 50 штук (5000 за 1 запуск дага).
Выгрузка сделана инкрементальной по дате обновления задачи с сохранением последней временной отметки в таблице stg.load_settings.
2. Загрузка информации об LTS версиях со страницы https://www.atlassian.com/software/jira/download-archives. 
Так как данные об LTS версиях прогружаются через вызов скриптов на странице и нет эндпоинтов для получения данных через API, то без использования сторонних сервисов или тяжелых библиотек типа Selenium получить этот список не получилось. 
Загрузка сделана полу-ручным методом: содержимое страницы простым копированием контента загружается в файл src/raw/versions.txt, а дальше файл уже парсится автоматически.

Первоначальная загрузка данных заняла около 3 часов, последующие не более 2 минут (при массовом обновлении ~ 150 задач)

#### Загрузка в ODS
ODS слой расположен в отдельной схеме на БД под управлением PostgreSQL.
Таблицы не имеют внешних ключей, проверяется уникальность ID. 
Данные очищаются от дублей, некорректных значений.
При обновлении объекта данные перезаписываются (UPSERT).

Схема слоя:

![ods](https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/db_scheme/2_ods_scheme.png)

На этом этапе разбираем полученные JSON объекты, очищаем данные и раскладываем их по соотвествующим таблицам.
Загрузка будет происходить инкрементально, с записью дат успешных выгрузок во вспомогательную таблицу в этой же схеме.

#### Загрузка в DDS
DDS слой расположен в отдельной схеме на БД под управлением PostgreSQL.
Схема слоя:

![dds](https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/db_scheme/3_dds_scheme.png)

Созданы таблицы по модели снежинка, приближенной к 3НФ с внешними ключами, ограничениями и проверками данных.
При обновлении объекта данные перезаписываются (UPSERT).

#### Построение витрин в CDM
CDM слой расположен в отдельной схеме на БД под управлением ClickHouse (облачный, на Yandex Cloud). 
Формируется на основе материализованного представления в PostgreSQL, обогащается полями и переносится в ClickHose через Apache Spark

Схема материализованного представления:

<img alt="cdm" src="https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/db_scheme/4_1_cdm_mat_view.png" width="200"/>

Схема слоя в ClickHouse:

<img alt="cdm" src="https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/db_scheme/4_2_cdm_click_table.png" width="200"/>

#### Пайплайн в Airflow
В Airflow реализовано 2 пайплайна:
1. Первоначальное создание всех слоев

![init_tables](https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/airflow/0_init_tables.png)

2. Загрузка данных последовательно во все слои. Слои объединены в TaskGroup

![load_tables](https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/airflow/0_full_atlassian_dag.png)


#### Структура проекта
* docs - директория для документации проекта
* src - директория c исходным кодом
* src/config - директория c файлами конфигурации
* src/dags - директория c пайплайнами для Airflow
* src/loaders - директория c кодом загрузчиков данных, разделенная по слоям. Содержит скрипты загрузки данных.
* src/raw - директория c сырыми данными для обработки. Содержит файл с копией контента страницы с версиями.
* src/sql - директория c SQL скриптами, используемыми при обработке данных, разделена по слоям.
* src/utils - директория со вспомогательными модулями. Содержит функции с повторяющимися фрагментами кода.

Utils:

* atlassian_util - функции для работы с REST API Atlassian
* check_util - функции для проверки качества данных
* clickhouse_util - функции для работы с Clickhouse
* connection_util - функции для получения данных для подключения к внешним сервисам. Реализована работа в локальном режиме (MODE = 'local') или режиме DAG (MODE = 'dag')
* dwh_util - функции для работы с DWH на базе PostgreSQL
* http_requests_util - функции для работы с HTTP запросами.
* loader_util.py - общие функции для загрузчиков данных
* spark_util.py - функции для работы со Spark.



#### Визуализация полученных данных в DataLens
1. Зависимость количества найденных багов по LTS и не-LTS релизам (количество багов по месяцам). 

![1_chart](https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/datalens/1_количество_багов_по_месяцам.png)

2. Скорость закрытия задач за период в разрезе Cloud - DC. (среднее время закрытие задач по месяцам)

![2_chart](https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/datalens/2_среднее_время_закрытия_задачи.png)

3. Зависимость скорости закрытия задачи от количества голосов за задачу (среднее время закрытия в зависиомости от количества голосов, округленного до 100)

![3_chart](https://github.com/Skylipper/de-atlassian-issues/blob/main/docs/images/datalens/3_скорость_решения_от_количества_голосов.png)

###### Выводы по визуализациям
1. Зависимость количества найденных багов по LTS и не-LTS релизам. До 2019 года количество найденных багов в LTS версиях было действительно меньше, чем в не-LTS. После 2019 ситуация поменялась на обратную.
2. Скорость закрытия задач за период в разрезе Cloud - DC. Судя по визуализации, среднее время закрытия для CLOUD версий действительно меньше.
3. Зависимость скорости закрытия задачи от количества голосов за задачу. Явной зависимости между количеством голосов и скоростью закрытия не вижу.

#### Примечания
Документация к REST API для облачной Atlassian JIRA - https://developer.atlassian.com/cloud/jira/platform/rest/v3/intro/#about

Информация об LTS релизах - https://www.atlassian.com/software/jira/download-archives